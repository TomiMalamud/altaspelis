{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "Baseline for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasmalamud/miniconda3/envs/recommender-test/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasmalamud/miniconda3/envs/recommender-test/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 237/237 [10:28<00:00,  2.65s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "# Load the dataset\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "\n",
    "# Load a pre-trained SentenceTransformer model\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=device)\n",
    "\n",
    "# Generate embeddings for the combined features\n",
    "print(\"Generating embeddings...\")\n",
    "\n",
    "# Generate separate embeddings\n",
    "embeddings = model.encode(df['content'].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(embeddings, embeddings)\n",
    "# Create a reverse map of indices and movie titles\n",
    "indices = pd.Series(df.index, index=df['tconst']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings...\n",
      "Embeddings saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to a file\n",
    "import numpy as np\n",
    "\n",
    "print(\"Saving embeddings...\")\n",
    "np.save('embeddings.npy', embeddings)\n",
    "\n",
    "print(\"Embeddings saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(tconst, df=df, embeddings=embeddings_better, top_n=30, content_weight=0.9, popularity_weight=0.1):\n",
    "    idx = indices[tconst]\n",
    "    movie_embedding = embeddings[idx].reshape(1, -1)\n",
    "    \n",
    "    # Compute cosine similarity on-the-fly\n",
    "    cosine_sim = cosine_similarity(movie_embedding, embeddings)[0]\n",
    "    \n",
    "    sim_scores = []\n",
    "    for i, content_sim in enumerate(cosine_sim):\n",
    "        combined_sim = (\n",
    "            content_weight * content_sim +\n",
    "            popularity_weight * df['popularity_score'].iloc[i]\n",
    "        )\n",
    "        sim_scores.append((i, combined_sim))\n",
    "    \n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]  # Get top N+1 (excluding the movie itself)\n",
    "    \n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    recommendations = df.iloc[movie_indices]\n",
    "    recommendations['similarity'] = [i[1] for i in sim_scores]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305         Wall Street: Money Never Sleeps\n",
      "16                   The Wolf of Wall Street\n",
      "2974                              Inside Job\n",
      "1693                             Margin Call\n",
      "1498                             Wall Street\n",
      "4325                              Dumb Money\n",
      "2805                     The Hudsucker Proxy\n",
      "2313                           Money Monster\n",
      "3946                               Arbitrage\n",
      "1482                          Trading Places\n",
      "57                       Catch Me If You Can\n",
      "623                           The Accountant\n",
      "4858                       Small Time Crooks\n",
      "836                               RocknRolla\n",
      "7498    Enron: The Smartest Guys in the Room\n",
      "7184                  Assault on Wall Street\n",
      "2168                                Paycheck\n",
      "154                          American Psycho\n",
      "1639                             Tower Heist\n",
      "773                                The Sting\n",
      "3352                          The Informant!\n",
      "1188                              Goldfinger\n",
      "2438                       The International\n",
      "2276                                Hustlers\n",
      "2644                          Going in Style\n",
      "3582                           The Money Pit\n",
      "640                               Uncut Gems\n",
      "3869                             Boiler Room\n",
      "2395                               Ambulance\n",
      "5214                              The Banker\n",
      "Name: title, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/nhcrhk997_lfsv2px600ylsw0000gn/T/ipykernel_2333/696735000.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommendations['similarity'] = [i[1] for i in sim_scores]\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "movie_tconst = 'tt1596363'  # Fight Club\n",
    "recommendations = get_recommendations(movie_tconst, top_n=30)\n",
    "print(recommendations['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
